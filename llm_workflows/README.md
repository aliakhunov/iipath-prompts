# LLM workflows

Prompts and protocols designed to improve, simplify, and stabilize work with Large Language Models.

This section focuses on **meta-level interaction with LLMs**: how prompts are structured, how context is managed, and how model behavior is constrained and verified.

The goal is not to solve domain tasks, but to make interaction with LLMs more reliable, controllable, and efficient.

## Use cases

Prompts in this directory are used for:

- enforcing behavioral or epistemic constraints (e.g. honesty, verification),
- reducing hallucinations and speculative answers,
- structuring complex multi-step interactions,
- transferring context between conversations or sessions,
- self-checking and validation of model outputs,
- improving predictability and consistency of LLM responses.

## Typical content

This section may include:

- behavioral protocols (e.g. truthfulness, self-verification),
- context extraction and transfer prompts,
- session initialization and reset frameworks,
- guardrails and failure-detection mechanisms,
- meta-prompts for controlling reasoning or output quality.

## Language note

Most prompts are written in Russian.

This is intentional, as precise control over LLM behavior strongly depends on language nuance and explicit instruction framing.
